{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from tensorflow import keras\n",
    "from keras.layers import Rescaling, Dense, Dropout, Input, LayerNormalization, Activation, Bidirectional, LSTM, TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow.python.keras.optimizers\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow.python.keras.mixed_precision.policy as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "train_x, train_onset = [], []\n",
    "valid_x, valid_onset = [], []\n",
    "\n",
    "model = None\n",
    "\n",
    "def dataSetGenerator(x_path, onset_path):\n",
    "    for a, b in zip(x_path, onset_path):\n",
    "        X, ONSET = [], []\n",
    "        X.append(np.load(a))\n",
    "        ONSET.append(np.load(b))\n",
    "\n",
    "        X = np.concatenate(X, axis=0)\n",
    "        ONSET = np.concatenate(ONSET, axis=0)\n",
    "\n",
    "        X = X / np.max(X)\n",
    "\n",
    "        model.reset_states()\n",
    "        for x, onset in zip(X, ONSET):\n",
    "            yield (x, onset)\n",
    "\n",
    "def buildModel():\n",
    "    input_layer = Input(batch_input_shape=(10, 100, 264), name='onset_input')\n",
    "\n",
    "    # Onset LSTM\n",
    "    onset_lstm = Bidirectional(LSTM(128, activation='tanh', return_sequences=True, stateful=True, name='onset_lstm'))(input_layer)\n",
    "\n",
    "    # Output\n",
    "    onset_out = TimeDistributed(Dense(88, activation='sigmoid', kernel_initializer='he_normal', name='onset_output'))(onset_lstm)\n",
    "\n",
    "    model = keras.Model(inputs=input_layer, outputs=onset_out)\n",
    "    return model\n",
    "\n",
    "def train(trainX, trainOnset, validX, validOnset):\n",
    "    for x_name, onset_name in zip(glob.glob(trainX), glob.glob(trainOnset)):\n",
    "        train_x.append(x_name)\n",
    "        train_onset.append(onset_name)\n",
    "\n",
    "    for x_name, onset_name in zip(glob.glob(validX), glob.glob(validOnset)):\n",
    "        valid_x.append(x_name)\n",
    "        valid_onset.append(onset_name)\n",
    "\n",
    "    input_signature = (tensorflow.float32, tensorflow.int8)\n",
    "    in_out_shape = ([100, 264], [100, 88])\n",
    "\n",
    "    global model\n",
    "    model = buildModel()\n",
    "    trainSet = tensorflow.data.Dataset.from_generator(dataSetGenerator, input_signature, in_out_shape, args=[train_x, train_onset])\n",
    "    validSet = tensorflow.data.Dataset.from_generator(dataSetGenerator, input_signature, in_out_shape, args=[valid_x, valid_onset])\n",
    "    trainSet = trainSet.batch(10, drop_remainder=True).prefetch(tensorflow.data.experimental.AUTOTUNE)\n",
    "    validSet = validSet.batch(10, drop_remainder=True).prefetch(tensorflow.data.experimental.AUTOTUNE)\n",
    "\n",
    "    checkpoint = ModelCheckpoint('onset_detector.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    early_stop = EarlyStopping(patience=5, monitor='val_loss', verbose=1, mode='auto')\n",
    "\n",
    "    opt = tensorflow.optimizers.Adam(learning_rate=0.0005)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    model.fit(trainSet, validation_data=validSet, epochs=2, shuffle=False, callbacks=[checkpoint, early_stop])\n",
    "    model.save('onset_last.h5')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train('preprocessed/trainX/*.npy', 'preprocessed/trainONSET/*.npy', 'preprocessed/validX/*.npy', 'preprocessed/validONSET/*.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
