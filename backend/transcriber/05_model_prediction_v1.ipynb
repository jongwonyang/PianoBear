{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 14:27:19.898729: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-21 14:27:20.119769: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-21 14:27:20.119795: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-21 14:27:20.121490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-21 14:27:20.213267: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1660 SUPER, compute capability 7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 14:27:22.524840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:27:22.542289: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:27:22.542312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:27:22.542491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:27:22.642374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:27:22.642421: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:27:22.642431: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:27:23.520872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:27:23.520912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:27:23.520918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-21 14:27:23.520935: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:27:23.520948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3914 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-07-21 14:27:23.798960: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 14:27:28.293306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 2s 7ms/step\n",
      "22/22 [==============================] - 1s 9ms/step\n",
      "saving...\n",
      "save complete\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from os.path import split, join\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "from pretty_midi import Note\n",
    "from pydub import AudioSegment\n",
    "from tensorflow import keras\n",
    "import tensorflow.python.keras.mixed_precision.policy as mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "AudioSegment.converter = 'ffmpeg'\n",
    "\n",
    "def one_to_midi(notes, offsets, file_name, time_per_frame):\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=1)\n",
    "\n",
    "    notes = notes.T\n",
    "    offsets = offsets.T\n",
    "    for pitch, hor in enumerate(notes):\n",
    "        nz = np.where(hor != 0)[0]\n",
    "        if len(nz) == 0:\n",
    "            continue\n",
    "\n",
    "        visit = np.zeros_like(hor, dtype=bool)\n",
    "        off = offsets[pitch]\n",
    "        for idx in nz:\n",
    "            i = idx\n",
    "            while i < len(off) and off[i] != 0:\n",
    "                visit[i] = True\n",
    "                i += 1\n",
    "\n",
    "        idx = 0\n",
    "        while idx < len(visit):\n",
    "            start_time = idx * time_per_frame\n",
    "            end_time = start_time\n",
    "\n",
    "            while idx < len(visit) and visit[idx]:\n",
    "                end_time += time_per_frame\n",
    "                idx += 1\n",
    "\n",
    "            if start_time != end_time:\n",
    "                instrument.notes.append(Note(\n",
    "                    velocity=100, pitch=pitch + 21, start=start_time, end=end_time))\n",
    "            idx += 1\n",
    "\n",
    "    print('saving...')\n",
    "    pm.instruments.append(instrument)\n",
    "    pm.write(file_name)\n",
    "    print('save complete')\n",
    "\n",
    "def preprocess_cqt(y, sr, one_seq, batch_size):\n",
    "    cqt = np.abs(librosa.cqt(y, sr=sr, fmin=librosa.midi_to_hz(21), n_bins=264, hop_length=160, bins_per_octave=36))\n",
    "    cqt = cqt.T / np.max(cqt)\n",
    "\n",
    "    pad_size = one_seq - (cqt.shape[0] % one_seq)\n",
    "    cqt = np.pad(cqt, ((0, pad_size), (0, 0)), mode='constant')\n",
    "\n",
    "    cqts = cqt.reshape(cqt.shape[0] // one_seq, one_seq, 264)\n",
    "\n",
    "    desired_shape = (batch_size * ((cqts.shape[0] + batch_size - 1) // batch_size), one_seq, 264)\n",
    "    padding_shape = (desired_shape[0] - cqts.shape[0], 0, 0)\n",
    "    cqts = np.pad(cqts, ((0, padding_shape[0]), (0, padding_shape[1]), (0, padding_shape[2])), mode='constant')\n",
    "\n",
    "    return cqts\n",
    "\n",
    "def predict_notes(len_model, onset_model, cqts, one_seq, batch_size):\n",
    "    len_result = len_model.predict(cqts, batch_size=batch_size)\n",
    "    onset_result = onset_model.predict(cqts, batch_size=batch_size)\n",
    "\n",
    "    onset = onset_result.reshape(-1, 88)\n",
    "    offset = len_result.reshape(-1, 88)\n",
    "\n",
    "    onset = (onset >= 0.5).astype(int)\n",
    "    offset = (offset >= 0.3).astype(int)\n",
    "\n",
    "    return onset, offset\n",
    "\n",
    "def test(X_test_path):\n",
    "    len_model = keras.models.load_model(\"models/offset_detector_v1.h5\")\n",
    "    onset_model = keras.models.load_model(\"models/onset_detector_v1.h5\")\n",
    "    print('model loaded')\n",
    "\n",
    "    y, sr = librosa.load(X_test_path, sr=16000)\n",
    "    one_seq = 100\n",
    "    batch_size = 10\n",
    "\n",
    "    cqts = preprocess_cqt(y, sr, one_seq, batch_size)\n",
    "    onset, offset = predict_notes(len_model, onset_model, cqts, one_seq, batch_size)\n",
    "\n",
    "    time_per_frame = librosa.frames_to_time(1, sr=sr, hop_length=160)\n",
    "    midi_file_path = join('data/', split(X_test_path)[-1][:-4] + '.mid')\n",
    "    one_to_midi(notes=onset, offsets=offset, file_name=midi_file_path, time_per_frame=time_per_frame)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test('data/tetris.mp3')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
