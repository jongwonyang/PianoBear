{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process-1 started with 80 files\n",
      "Process-2 started with 80 files\n",
      "Process-3 started with 80 files\n",
      "Process-4 started with 80 files\n",
      "Process-5 started with 80 files\n",
      "Process-6 started with 80 files\n",
      "Process-7 started with 80 files\n",
      "Process-8 started with 80 files\n",
      "Process-9 started with 80 files\n",
      "Process-10 started with 80 files\n",
      "Process-11 started with 80 files\n",
      "Process-12 started with 82 files\n",
      "Process-6 finished\n",
      "Process-8 finished\n",
      "Process-1 finished\n",
      "Process-2 finished\n",
      "Process-9 finished\n",
      "Process-10 finished\n",
      "Process-4 finished\n",
      "Process-18 started with 11 filesProcess-14 started with 11 files\n",
      "Process-20 started with 11 filesProcess-13 started with 11 filesProcess-15 started with 11 filesProcess-17 started with 11 filesProcess-16 started with 11 filesProcess-24 started with 16 files\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Process-22 started with 11 filesProcess-23 started with 11 filesProcess-19 started with 11 files\n",
      "Process-21 started with 11 files\n",
      "\n",
      "\n",
      "\n",
      "Process-16 finished\n",
      "Process-18 finished\n",
      "Process-15 finished\n",
      "Process-17 finished\n",
      "Process-19 finished\n",
      "Process-14 finished\n",
      "Process-13 finished\n",
      "Process-21 finished\n",
      "Process-24 finished\n",
      "Process-20 finished\n",
      "Process-28 started with 14 filesProcess-25 started with 14 filesProcess-29 started with 14 files\n",
      "Process-30 started with 14 files\n",
      "Process-31 started with 14 files\n",
      "Process-32 started with 14 files\n",
      "Process-33 started with 14 files\n",
      "\n",
      "\n",
      "Process-34 started with 14 files\n",
      "Process-35 started with 14 files\n",
      "Process-26 started with 14 files\n",
      "Process-36 started with 23 files\n",
      "Process-27 started with 14 files\n",
      "Process-26 finished\n",
      "Process-32 finished\n",
      "Process-30 finished\n",
      "Process-28 finished\n",
      "Process-33 finished\n",
      "Process-36 finished\n",
      "Process-27 finished\n",
      "Process-25 finished\n",
      "Process-34 finished\n",
      "Process-29 finished\n",
      "Process-35 finished\n",
      "Process-31 finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import librosa\n",
    "import note_seq\n",
    "from multiprocessing import Process, current_process, cpu_count\n",
    "\n",
    "DATA_DIR = 'data/maestro-v3.0.0'\n",
    "SAVE_DIR = 'data/preprocessed'\n",
    "\n",
    "def process_midi_audio(midi_path, audio_path, cqt_save_path, onset_save_path, offset_save_path):\n",
    "    try:\n",
    "        # 파일 로드 및 CQT 변환\n",
    "        y, sr = librosa.load(audio_path, sr=16000)\n",
    "        cqt = librosa.cqt(y, sr=sr, fmin=librosa.midi_to_hz(21), n_bins=264, hop_length=160, bins_per_octave=36)\n",
    "        cqt = np.abs(cqt).T\n",
    "        cqt = np.pad(cqt, ((0, 10), (0, 0)), mode='constant')\n",
    "\n",
    "        # 빈 결과 배열 생성\n",
    "        onset = np.zeros((cqt.shape[0], 88))\n",
    "        offset = np.zeros((cqt.shape[0], 88))\n",
    "\n",
    "        # 패딩\n",
    "        one_seq = 100\n",
    "        pad_size = one_seq - (cqt.shape[0] % one_seq)\n",
    "        cqt = np.pad(cqt, ((0, pad_size), (0, 0)), mode='constant')\n",
    "        onset = np.pad(onset, ((0, pad_size), (0, 0)), mode='constant')\n",
    "        offset = np.pad(offset, ((0, pad_size), (0, 0)), mode='constant')\n",
    "\n",
    "        # MIDI 노트 처리\n",
    "        note_seq_data = note_seq.midi_file_to_note_sequence(midi_path)\n",
    "        for note in note_seq_data.notes:\n",
    "            pitch = note.pitch - 21\n",
    "            start_frame = int(note.start_time * 100)\n",
    "            end_frame = int(note.end_time * 100)\n",
    "            onset[start_frame:start_frame + 4, pitch] = 1\n",
    "            offset[start_frame:end_frame, pitch] = 1\n",
    "\n",
    "        # 크기 변환\n",
    "        cqt = cqt.reshape(cqt.shape[0] // one_seq, one_seq, 264)\n",
    "        onset = onset.reshape(onset.shape[0] // one_seq, one_seq, 88)\n",
    "        offset = offset.reshape(offset.shape[0] // one_seq, one_seq, 88)\n",
    "\n",
    "        file_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "        np.save(os.path.join(cqt_save_path, file_name), cqt)\n",
    "        np.save(os.path.join(onset_save_path, file_name), onset)\n",
    "        np.save(os.path.join(offset_save_path, file_name), offset)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {midi_path} and {audio_path}: {e}\")\n",
    "\n",
    "def process_files(midi_paths, audio_paths, cqt_save_dir, onset_save_dir, offset_save_dir):\n",
    "    process_name = current_process().name\n",
    "    print(f\"{process_name} started with {len(midi_paths)} files\")\n",
    "    for midi_file, audio_file in zip(midi_paths, audio_paths):\n",
    "        midi_path = os.path.join(DATA_DIR, midi_file)\n",
    "        audio_path = os.path.join(DATA_DIR, audio_file)\n",
    "        process_midi_audio(midi_path, audio_path, cqt_save_dir, onset_save_dir, offset_save_dir)\n",
    "    print(f\"{process_name} finished\")\n",
    "\n",
    "def main(save_dir, use_multiprocessing=True, num_processes=None):\n",
    "    if num_processes is None:\n",
    "        num_processes = cpu_count()  # CPU 코어 수만큼 프로세스 설정\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, 'trainX'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, 'validX'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, 'trainONSET'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, 'validONSET'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, 'trainOFFSET'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, 'validOFFSET'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, 'testX'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, 'testONSET'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_dir, 'testOFFSET'), exist_ok=True)\n",
    "\n",
    "    train_midi_paths, train_audio_paths = [], []\n",
    "    val_midi_paths, val_audio_paths = [], []\n",
    "    test_midi_paths, test_audio_paths = [], []\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, 'maestro-v3.0.0.csv'), 'r', encoding='utf-8') as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            if row['split'] == 'train':\n",
    "                train_midi_paths.append(row['midi_filename'])\n",
    "                train_audio_paths.append(row['audio_filename'])\n",
    "            elif row['split'] == 'validation':\n",
    "                val_midi_paths.append(row['midi_filename'])\n",
    "                val_audio_paths.append(row['audio_filename'])\n",
    "            elif row['split'] == 'test':\n",
    "                test_midi_paths.append(row['midi_filename'])\n",
    "                test_audio_paths.append(row['audio_filename'])\n",
    "\n",
    "    if use_multiprocessing:\n",
    "        # Training data processing\n",
    "        train_segment_length = len(train_midi_paths) // num_processes\n",
    "        processes = []\n",
    "\n",
    "        for i in range(num_processes):\n",
    "            start_index = i * train_segment_length\n",
    "            end_index = None if i == num_processes - 1 else (i + 1) * train_segment_length\n",
    "            p = Process(target=process_files, args=(\n",
    "                train_midi_paths[start_index:end_index], train_audio_paths[start_index:end_index],\n",
    "                os.path.join(save_dir, 'trainX'), os.path.join(save_dir, 'trainONSET'), os.path.join(save_dir, 'trainOFFSET')))\n",
    "            processes.append(p)\n",
    "            p.start()\n",
    "\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "\n",
    "        # Validation data processing\n",
    "        val_segment_length = len(val_midi_paths) // num_processes\n",
    "        val_processes = []\n",
    "\n",
    "        for i in range(num_processes):\n",
    "            start_index = i * val_segment_length\n",
    "            end_index = None if i == num_processes - 1 else (i + 1) * val_segment_length\n",
    "            p = Process(target=process_files, args=(\n",
    "                val_midi_paths[start_index:end_index], val_audio_paths[start_index:end_index],\n",
    "                os.path.join(save_dir, 'validX'), os.path.join(save_dir, 'validONSET'), os.path.join(save_dir, 'validOFFSET')))\n",
    "            val_processes.append(p)\n",
    "            p.start()\n",
    "\n",
    "        for p in val_processes:\n",
    "            p.join()\n",
    "\n",
    "        # Test data processing\n",
    "        test_segment_length = len(test_midi_paths) // num_processes\n",
    "        test_processes = []\n",
    "\n",
    "        for i in range(num_processes):\n",
    "            start_index = i * test_segment_length\n",
    "            end_index = None if i == num_processes- 1 else (i + 1) * test_segment_length\n",
    "            p = Process(target=process_files, args=(\n",
    "                test_midi_paths[start_index:end_index], test_audio_paths[start_index:end_index],\n",
    "                os.path.join(save_dir, 'testX'), os.path.join(save_dir, 'testONSET'), os.path.join(save_dir, 'testOFFSET')\n",
    "            ))\n",
    "            test_processes.append(p)\n",
    "            p.start()\n",
    "\n",
    "        for p in test_processes:\n",
    "            p.join()\n",
    "    else:\n",
    "        # Training data processing\n",
    "        process_files(train_midi_paths, train_audio_paths,\n",
    "                      os.path.join(save_dir, 'trainX'),\n",
    "                      os.path.join(save_dir, 'trainONSET'),\n",
    "                      os.path.join(save_dir, 'trainOFFSET'))\n",
    "        # Validation data processing\n",
    "        process_files(val_midi_paths, val_audio_paths,\n",
    "                      os.path.join(save_dir, 'validX'),\n",
    "                      os.path.join(save_dir, 'validONSET'),\n",
    "                      os.path.join(save_dir, 'validOFFSET'))\n",
    "        # Test data processing\n",
    "        process_files(test_midi_paths, test_audio_paths,\n",
    "                      os.path.join(save_dir, 'testX'),\n",
    "                      os.path.join(save_dir, 'testONSET'),\n",
    "                      os.path.join(save_dir, 'testOFFSET'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(SAVE_DIR, use_multiprocessing=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
