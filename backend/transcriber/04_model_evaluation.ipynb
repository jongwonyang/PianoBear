{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onset 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 17:54:14.244967: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-21 17:54:14.417044: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-21 17:54:14.417084: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-21 17:54:14.417509: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-21 17:54:14.477947: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 17:54:16.854455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 17:54:16.874026: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 17:54:16.874058: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 17:54:16.875447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 17:54:16.875476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 17:54:16.875487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 17:54:18.594980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 17:54:18.595046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 17:54:18.595053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-21 17:54:18.595076: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 17:54:18.595098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3618 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1660 SUPER, compute capability 7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 17:54:22.672591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 17:54:22.955798: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 17:54:25.810249: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: data_generator() missing 1 required positional argument: 'model'\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 859, in get_iterator\n",
      "    return self._iterators[iterator_id]\n",
      "\n",
      "KeyError: 0\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 861, in get_iterator\n",
      "    iterator = iter(self._generator(*self._args.pop(iterator_id)))\n",
      "\n",
      "  File \"/tmp/ipykernel_54863/4291537393.py\", line 38, in <lambda>\n",
      "    test_set = tf.data.Dataset.from_generator(lambda: data_generator(test_cqt_paths, test_stft_paths, test_onset_paths), output_signature=output_signature)\n",
      "\n",
      "TypeError: data_generator() missing 1 required positional argument: 'model'\n",
      "\n",
      "\n",
      "2024-07-21 17:54:25.810481: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 3268497392412525023\n",
      "2024-07-21 17:54:25.810504: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 8095481874824052659\n",
      "2024-07-21 17:54:25.810540: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10550386172362433720\n",
      "2024-07-21 17:54:25.819328: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: KeyError: 0\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 859, in get_iterator\n",
      "    return self._iterators[iterator_id]\n",
      "\n",
      "KeyError: 0\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 861, in get_iterator\n",
      "    iterator = iter(self._generator(*self._args.pop(iterator_id)))\n",
      "\n",
      "KeyError: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: data_generator() missing 1 required positional argument: 'model'\nTraceback (most recent call last):\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 859, in get_iterator\n    return self._iterators[iterator_id]\n\nKeyError: 0\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 861, in get_iterator\n    iterator = iter(self._generator(*self._args.pop(iterator_id)))\n\n  File \"/tmp/ipykernel_54863/4291537393.py\", line 38, in <lambda>\n    test_set = tf.data.Dataset.from_generator(lambda: data_generator(test_cqt_paths, test_stft_paths, test_onset_paths), output_signature=output_signature)\n\nTypeError: data_generator() missing 1 required positional argument: 'model'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) INVALID_ARGUMENT:  TypeError: data_generator() missing 1 required positional argument: 'model'\nTraceback (most recent call last):\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 859, in get_iterator\n    return self._iterators[iterator_id]\n\nKeyError: 0\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 861, in get_iterator\n    iterator = iter(self._generator(*self._args.pop(iterator_id)))\n\n  File \"/tmp/ipykernel_54863/4291537393.py\", line 38, in <lambda>\n    test_set = tf.data.Dataset.from_generator(lambda: data_generator(test_cqt_paths, test_stft_paths, test_onset_paths), output_signature=output_signature)\n\nTypeError: data_generator() missing 1 required positional argument: 'model'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_4039]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/preprocessed/testX/cqt/*.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/preprocessed/testX/stft/*.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/preprocessed/testONSET/*.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(test_cqt, test_stft, test_onset)\u001b[0m\n\u001b[1;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/onset_detector.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39mload(file)) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m test_cqt_paths]) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[0;32m---> 45\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: data_generator() missing 1 required positional argument: 'model'\nTraceback (most recent call last):\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 859, in get_iterator\n    return self._iterators[iterator_id]\n\nKeyError: 0\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 861, in get_iterator\n    iterator = iter(self._generator(*self._args.pop(iterator_id)))\n\n  File \"/tmp/ipykernel_54863/4291537393.py\", line 38, in <lambda>\n    test_set = tf.data.Dataset.from_generator(lambda: data_generator(test_cqt_paths, test_stft_paths, test_onset_paths), output_signature=output_signature)\n\nTypeError: data_generator() missing 1 required positional argument: 'model'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) INVALID_ARGUMENT:  TypeError: data_generator() missing 1 required positional argument: 'model'\nTraceback (most recent call last):\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 859, in get_iterator\n    return self._iterators[iterator_id]\n\nKeyError: 0\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jongwon/workspace/S11P12B103/backend/transcriber/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 861, in get_iterator\n    iterator = iter(self._generator(*self._args.pop(iterator_id)))\n\n  File \"/tmp/ipykernel_54863/4291537393.py\", line 38, in <lambda>\n    test_set = tf.data.Dataset.from_generator(lambda: data_generator(test_cqt_paths, test_stft_paths, test_onset_paths), output_signature=output_signature)\n\nTypeError: data_generator() missing 1 required positional argument: 'model'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_4039]"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def data_generator(x_paths, onset_paths):\n",
    "    for x_path, onset_path in zip(x_paths, onset_paths):\n",
    "        X = np.load(x_path)\n",
    "        ONSET = np.load(onset_path)\n",
    "\n",
    "        X = X / np.max(X)  # 정규화\n",
    "\n",
    "        for x, onset in zip(X, ONSET):\n",
    "            yield (x, onset)  # 한 세그먼트씩 반환\n",
    "\n",
    "def evaluate(test_x, test_onset):\n",
    "    test_x_paths, test_onset_paths = [], []\n",
    "\n",
    "    for x_path, onset_path in zip(glob.glob(test_x), glob.glob(test_onset)):\n",
    "        test_x_paths.append(x_path)\n",
    "        test_onset_paths.append(onset_path)\n",
    "\n",
    "    output_signature = (tf.TensorSpec(shape=(100, 264), dtype=tf.float32), tf.TensorSpec(shape=(100, 88), dtype=tf.int8))\n",
    "\n",
    "    batch_size = 10\n",
    "\n",
    "    test_set = tf.data.Dataset.from_generator(lambda: data_generator(test_x_paths, test_onset_paths), output_signature=output_signature)\n",
    "    test_set = test_set.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    model = load_model('models/onset_detector.h5')\n",
    "\n",
    "    steps_per_epoch = sum([len(np.load(file)) for file in test_x_paths]) // batch_size\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_set, steps=steps_per_epoch, verbose=2)\n",
    "    print(f'Test Loss: {loss}')\n",
    "    print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    evaluate('data/preprocessed/testX/*.npy', 'data/preprocessed/testONSET/*.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offset 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 14:34:03.278834: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-21 14:34:03.305400: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-21 14:34:03.305427: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-21 14:34:03.305440: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-21 14:34:03.311672: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 14:34:05.130574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:34:05.136194: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:34:05.136219: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:34:05.137879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:34:05.137906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:34:05.137918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:34:05.615744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:34:05.615782: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:34:05.615787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-21 14:34:05.615806: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-21 14:34:05.615822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3608 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-07-21 14:34:08.194959: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-21 14:34:13.981283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7237/7237 - 47s - loss: 0.0509 - accuracy: 0.2616 - 47s/epoch - 6ms/step\n",
      "Test Loss: 0.05085653439164162\n",
      "Test Accuracy: 0.26164668798446655\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def data_generator(x_paths, offset_paths):\n",
    "    for x_path, onset_path in zip(x_paths, offset_paths):\n",
    "        X = np.load(x_path)\n",
    "        OFFSET = np.load(onset_path)\n",
    "\n",
    "        X = X / np.max(X)  # 정규화\n",
    "\n",
    "        for x, onset in zip(X, OFFSET):\n",
    "            yield (x, onset)  # 한 세그먼트씩 반환\n",
    "\n",
    "def evaluate(test_x, test_offset):\n",
    "    test_x_paths, test_offset_paths = [], []\n",
    "\n",
    "    for x_path, offset_path in zip(glob.glob(test_x), glob.glob(test_offset)):\n",
    "        test_x_paths.append(x_path)\n",
    "        test_offset_paths.append(offset_path)\n",
    "\n",
    "    output_signature = (tf.TensorSpec(shape=(100, 264), dtype=tf.float32), tf.TensorSpec(shape=(100, 88), dtype=tf.int8))\n",
    "\n",
    "    batch_size = 10\n",
    "\n",
    "    test_set = tf.data.Dataset.from_generator(lambda: data_generator(test_x_paths, test_offset_paths), output_signature=output_signature)\n",
    "    test_set = test_set.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    model = load_model('models/offset_detector.h5')\n",
    "\n",
    "    steps_per_epoch = sum([len(np.load(file)) for file in test_x_paths]) // batch_size\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_set, steps=steps_per_epoch, verbose=2)\n",
    "    print(f'Test Loss: {loss}')\n",
    "    print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    evaluate('data/preprocessed/testX/*.npy', 'data/preprocessed/testOFFSET/*.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
